{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"modelTA.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPt8aTrQXB/TEfg93UGm1qe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"Y7bGZhcb2YRq","executionInfo":{"status":"ok","timestamp":1643915174090,"user_tz":-300,"elapsed":6695,"user":{"displayName":"Muhammad Wasif Ijaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmhhTe_V2U5qTcJA25bOqqETU87ndedAsNq9qCPw=s64","userId":"08785971833040696136"}}},"outputs":[],"source":["from __future__ import absolute_import\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.autograd import Variable\n","import torchvision"]},{"cell_type":"code","source":["class ResNet50TA(nn.Module):\n","    def __init__(self, num_classes, loss={'xent'}, **kwargs):\n","        super(ResNet50TA, self).__init__()\n","        self.loss = loss\n","        resnet50 = torchvision.models.resnet50(pretrained=True)\n","        self.base = nn.Sequential(*list(resnet50.children())[:-2])\n","        self.att_gen = 'softmax' # method for attention generation: softmax or sigmoid\n","        self.feat_dim = 2048 # feature dimension\n","        self.middle_dim = 256 # middle layer dimension\n","        self.classifier = nn.Linear(self.feat_dim, num_classes)\n","        self.attention_conv = nn.Conv2d(self.feat_dim, self.middle_dim, [7,4]) # 7,4 cooresponds to 224, 112 input image size\n","        self.attention_tconv = nn.Conv1d(self.middle_dim, 1, 3, padding=1)\n","    def forward(self, x):\n","        b = x.size(0)\n","        t = x.size(1)\n","        x = x.view(b*t, x.size(2), x.size(3), x.size(4))\n","        x = self.base(x)\n","        a = F.relu(self.attention_conv(x))\n","        a = a.view(b, t, self.middle_dim)\n","        a = a.permute(0,2,1)\n","        a = F.relu(self.attention_tconv(a))\n","        a = a.view(b, t)\n","        x = F.avg_pool2d(x, x.size()[2:])\n","        if self. att_gen=='softmax':\n","            a = F.softmax(a, dim=1)\n","        elif self.att_gen=='sigmoid':\n","            a = F.sigmoid(a)\n","            a = F.normalize(a, p=1, dim=1)\n","        else: \n","            raise KeyError(\"Unsupported attention generation function: {}\".format(self.att_gen))\n","        x = x.view(b, t, -1)\n","        a = torch.unsqueeze(a, -1)\n","        a = a.expand(b, t, self.feat_dim)\n","        att_x = torch.mul(x,a)\n","        att_x = torch.sum(att_x,1)\n","        \n","        f = att_x.view(b,self.feat_dim)\n","        if not self.training:\n","            return f\n","        y = self.classifier(f)\n","\n","        if self.loss == {'xent'}:\n","            return y\n","        elif self.loss == {'xent', 'htri'}:\n","            return y, f\n","        elif self.loss == {'cent'}:\n","            return y, f\n","        else:\n","            raise KeyError(\"Unsupported loss: {}\".format(self.loss))"],"metadata":{"id":"wTvw2aK89U0q","executionInfo":{"status":"ok","timestamp":1643915198739,"user_tz":-300,"elapsed":373,"user":{"displayName":"Muhammad Wasif Ijaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmhhTe_V2U5qTcJA25bOqqETU87ndedAsNq9qCPw=s64","userId":"08785971833040696136"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\n","    \"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"metadata":{"id":"EHW4rRPJ_m2j","executionInfo":{"status":"ok","timestamp":1643915608919,"user_tz":-300,"elapsed":20,"user":{"displayName":"Muhammad Wasif Ijaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmhhTe_V2U5qTcJA25bOqqETU87ndedAsNq9qCPw=s64","userId":"08785971833040696136"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def train(model, criterion_xent, criterion_htri, optimizer, trainloader, use_gpu):\n","    model.train()\n","    losses = AverageMeter()\n","\n","    for batch_idx, (imgs, pids, _) in enumerate(trainloader):\n","        if use_gpu:\n","            imgs, pids = imgs.cuda(), pids.cuda()\n","        imgs, pids = Variable(imgs), Variable(pids)\n","        outputs, features = model(imgs)\n","\n","        # combine hard triplet loss with cross entropy loss\n","        xent_loss = criterion_xent(outputs, pids)\n","        htri_loss = criterion_htri(features, pids)\n","        loss = xent_loss + htri_loss\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        losses.update(loss.data[0], pids.size(0))\n","\n","        #if (batch_idx+1) % args.print_freq == 0:\n","        print(\"Batch {}/{}\\t Loss {:.6f} ({:.6f})\".format(batch_idx+1, len(trainloader), losses.val, losses.avg))"],"metadata":{"id":"f5wZY11iAX4e"},"execution_count":null,"outputs":[]}]}