{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93d95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a99590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSM_CAA_Loss():\n",
    "    def __init__(self, alpha=1.2, l=0.5, use_gpu=True, batch_size=32):\n",
    "        self.use_gpu = use_gpu\n",
    "        self.alpha = 1.2 # margin of weighted contrastive loss, as mentioned in the paper \n",
    "        self.l = 0.5 #  hyperparameter controlling weights of positive set and the negative set  \n",
    "        self.osm_sigma = 0.8  #\\sigma OSM (0.8) as mentioned in paper\n",
    "        self.n = batch_size \n",
    "        \n",
    "    def forward(self, x, labels , embd):\n",
    "        '''\n",
    "        x : feature vector : (n x d)\n",
    "        labels : (n,)\n",
    "        embd : Fully Connected weights of classification layer (dxC), C is the number of classes: represents the vectors for class\n",
    "        '''\n",
    "        x = tf.math.l2_normalize(x, 1)\n",
    "        n = self.n\n",
    "        r = tf.ones([n, 1], tf.float32)\n",
    "        #         r = tf.reduce_sum(x*x, 1)\n",
    "        #         r = tf.reshape(r, [-1, 1])\n",
    "        dist = r - 2*tf.matmul(x, tf.transpose(x)) + tf.transpose(r)\n",
    "        dist = tf.math.sqrt(dist)\n",
    "        dist = tf.clip_by_value(dist, clip_value_min=tf.constant(1e-12) , clip_value_max=tf.constant(1e12)) #0 value sometimes becomes nan\n",
    "        \n",
    "        p_mask = tf.cast(tf.equal(labels[:, tf.newaxis], labels[tf.newaxis, :]), tf.float32)\n",
    "        n_mask = 1- p_mask\n",
    "        \n",
    "        S = tf.exp(-1 * dist / (self.osm_sigma * self.osm_sigma ) )\n",
    "        S_  = tf.clip_by_value(tf.nn.relu(self.alpha - dist), clip_value_min=tf.constant(1e-12) , clip_value_max=tf.constant(1e12)) \n",
    "        S = S * p_mask\n",
    "        S_ = S_ * n_mask\n",
    "        S  = S + S_\n",
    "\n",
    "        embd = tf.math.l2_normalize(embd, 0)\n",
    "        denom = tf.reduce_sum(tf.exp(tf.matmul(x , embd)),1)\n",
    "        num =  tf.exp (tf.reduce_sum( x * tf.transpose(tf.gather(embd , labels , axis=1)) , 1 ))\n",
    "        \n",
    "        atten_class = num / denom\n",
    "        temp = tf.tile(tf.expand_dims(atten_class, 0),[n,1])\n",
    "        A =  tf.math.minimum(temp , tf.transpose(temp))\n",
    "\n",
    "        W = S * A \n",
    "        W_P = W * p_mask\n",
    "        W_N = W * n_mask\n",
    "        W_P = W_P * (1 - tf.eye(n))\n",
    "        W_N = W_N * (1 - tf.eye(n))\n",
    "\n",
    "        L_P =  tf.reduce_sum(W_P * tf.pow(dist,2) ) / (2 * tf.reduce_sum(W_P) )\n",
    "        L_N  = tf.reduce_sum(W_N * tf.pow(S_ , 2) ) / (2 * tf.reduce_sum(W_N) )\n",
    "\n",
    "        L = (1- self.l) * L_P + self.l * L_N\n",
    "\n",
    "        return L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4964fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
